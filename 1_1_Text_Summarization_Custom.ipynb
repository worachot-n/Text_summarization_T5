{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.1 Text_Summarization_Custom",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM1g2XZVSTC1zcFW5mlKOht",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/worachot-n/Text_summarization_T5/blob/main/1_1_Text_Summarization_Custom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0J9IBaBMfm1",
        "outputId": "abca27f3-a340-4808-9232-7fc2f7d45e35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece\n",
        "!pip install transformers\n",
        "!pip install rich[jupyter]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRTA4OL4MpCP",
        "outputId": "acb0b018-9d8e-4cb0-a8f4-f62f3c8e4549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 4.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 4.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 51.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Collecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 40.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 45.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n",
            "Collecting rich[jupyter]\n",
            "  Downloading rich-12.0.1-py3-none-any.whl (224 kB)\n",
            "\u001b[K     |████████████████████████████████| 224 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 6.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions<5.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from rich[jupyter]) (3.10.0.2)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich[jupyter]) (2.6.1)\n",
            "Requirement already satisfied: ipywidgets<8.0.0,>=7.5.1 in /usr/local/lib/python3.7/dist-packages (from rich[jupyter]) (7.7.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.2.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (5.2.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (4.10.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (1.1.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (3.6.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (5.1.1)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (5.3.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (57.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.7.5)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (4.9.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (5.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (4.11.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (21.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.18.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (3.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (1.15.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (5.3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (2.11.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (1.8.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.13.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (2.8.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (2.0.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (4.1.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.6.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (1.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (21.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.5.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (3.0.7)\n",
            "Installing collected packages: commonmark, rich\n",
            "Successfully installed commonmark-0.9.1 rich-12.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Kaggle/BBC_News_Summary.csv\")"
      ],
      "metadata": {
        "id": "MICsXjGZMpiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "da8IYf2nMtqS",
        "outputId": "fc5fbf8a-a870-4136-c091-4ffe334e278b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0                                           articles  \\\n",
              "2031        2031  GM issues 2005 profits warning\\n\\nGeneral Moto...   \n",
              "2049        2049  Gazprom 'in $36m back-tax claim'\\n\\nThe nuclea...   \n",
              "2209        2209  Euronext 'poised to make LSE bid'\\n\\nPan-Europ...   \n",
              "548          548  Cole refuses to blame van Persie\\n\\nAshley Col...   \n",
              "1901        1901  US company admits Benin bribery\\n\\nA US defenc...   \n",
              "1581        1581  Campaigners attack MTV 'sleaze'\\n\\nMTV has bee...   \n",
              "6              6  Tories pledge free sports lessons\\n\\nChildren ...   \n",
              "1356        1356  Tautou 'to star in Da Vinci film'\\n\\nFrench ac...   \n",
              "1174        1174  Broadband fuels online change\\n\\nFast web acce...   \n",
              "629          629  Yelling takes Cardiff hat-trick\\n\\nEuropean cr...   \n",
              "\n",
              "                                              summaries     categories  \n",
              "2031  Nearly 9,000 business leaders in 104 countries...       business  \n",
              "2049  More than 2,000 business and political leaders...       business  \n",
              "2209  Yukos will return to a US court on Wednesday t...       business  \n",
              "548   \"It cost us the game against Wales but it has ...          sport  \n",
              "1901  The government of Nigeria is hoping to triple ...       business  \n",
              "1581  Irish rock band U2 are to play live at the Gra...  entertainment  \n",
              "6     But according to the BBC poll, 61% said the is...       politics  \n",
              "1356  Cinematographer John Mathieson, who was nomina...  entertainment  \n",
              "1174  There are now at least three working alternati...           tech  \n",
              "629   Day has been displaced by the arrival of Simon...          sport  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f11278b-66c5-445a-8dbf-de6a8f8b7d4d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>articles</th>\n",
              "      <th>summaries</th>\n",
              "      <th>categories</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2031</th>\n",
              "      <td>2031</td>\n",
              "      <td>GM issues 2005 profits warning\\n\\nGeneral Moto...</td>\n",
              "      <td>Nearly 9,000 business leaders in 104 countries...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2049</th>\n",
              "      <td>2049</td>\n",
              "      <td>Gazprom 'in $36m back-tax claim'\\n\\nThe nuclea...</td>\n",
              "      <td>More than 2,000 business and political leaders...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2209</th>\n",
              "      <td>2209</td>\n",
              "      <td>Euronext 'poised to make LSE bid'\\n\\nPan-Europ...</td>\n",
              "      <td>Yukos will return to a US court on Wednesday t...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>548</th>\n",
              "      <td>548</td>\n",
              "      <td>Cole refuses to blame van Persie\\n\\nAshley Col...</td>\n",
              "      <td>\"It cost us the game against Wales but it has ...</td>\n",
              "      <td>sport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1901</th>\n",
              "      <td>1901</td>\n",
              "      <td>US company admits Benin bribery\\n\\nA US defenc...</td>\n",
              "      <td>The government of Nigeria is hoping to triple ...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1581</th>\n",
              "      <td>1581</td>\n",
              "      <td>Campaigners attack MTV 'sleaze'\\n\\nMTV has bee...</td>\n",
              "      <td>Irish rock band U2 are to play live at the Gra...</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>Tories pledge free sports lessons\\n\\nChildren ...</td>\n",
              "      <td>But according to the BBC poll, 61% said the is...</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1356</th>\n",
              "      <td>1356</td>\n",
              "      <td>Tautou 'to star in Da Vinci film'\\n\\nFrench ac...</td>\n",
              "      <td>Cinematographer John Mathieson, who was nomina...</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1174</th>\n",
              "      <td>1174</td>\n",
              "      <td>Broadband fuels online change\\n\\nFast web acce...</td>\n",
              "      <td>There are now at least three working alternati...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>629</th>\n",
              "      <td>629</td>\n",
              "      <td>Yelling takes Cardiff hat-trick\\n\\nEuropean cr...</td>\n",
              "      <td>Day has been displaced by the arrival of Simon...</td>\n",
              "      <td>sport</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f11278b-66c5-445a-8dbf-de6a8f8b7d4d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4f11278b-66c5-445a-8dbf-de6a8f8b7d4d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4f11278b-66c5-445a-8dbf-de6a8f8b7d4d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_business = df.loc[df['categories'] == 'business']"
      ],
      "metadata": {
        "id": "tcz7rxMrjbF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_business = df_business[['articles', 'summaries']]\n",
        "df_business"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "1kBUyxewjlSt",
        "outputId": "a239785b-e703-44b7-b276-2395a042141f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               articles  \\\n",
              "1715  EU 'too slow' on economic reforms\\n\\nMost EU c...   \n",
              "1716  Glazer makes new Man Utd approach\\n\\nMalcolm G...   \n",
              "1717  Five million Germans out of work\\n\\nGermany's ...   \n",
              "1718  Axa Sun Life cuts bonus payments\\n\\nLife insur...   \n",
              "1719  Amex shares up on spin-off news\\n\\nShares in A...   \n",
              "...                                                 ...   \n",
              "2220  GE sees 'excellent' world economy\\n\\nUS behemo...   \n",
              "2221  Millions 'to lose textile jobs'\\n\\nMillions of...   \n",
              "2222  US to rule on Yukos refuge call\\n\\nYukos has s...   \n",
              "2223  Business confidence dips in Japan\\n\\nBusiness ...   \n",
              "2224  Wall Street cheers Bush victory\\n\\nThe US stoc...   \n",
              "\n",
              "                                              summaries  \n",
              "1715  Senator Kerry attacked President Bush's econom...  \n",
              "1716  A slimming aid made from a southern African ca...  \n",
              "1717  Job creation was one of last year's main conce...  \n",
              "1718  Malcolm Glazer has made a fresh approach to bu...  \n",
              "1719  If admitted into the EU, Turkey would contribu...  \n",
              "...                                                 ...  \n",
              "2220  The WTO said that many developing countries su...  \n",
              "2221  Reuters news agency reported that Iraq's Oil M...  \n",
              "2222  Parmalat has sued 45 banks as it tries to recl...  \n",
              "2223  Bombardier said restructuring plans drawn up b...  \n",
              "2224  The Brazilian government has played down claim...  \n",
              "\n",
              "[510 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bfcb231b-3274-4085-8b82-091f9de79904\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>articles</th>\n",
              "      <th>summaries</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1715</th>\n",
              "      <td>EU 'too slow' on economic reforms\\n\\nMost EU c...</td>\n",
              "      <td>Senator Kerry attacked President Bush's econom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1716</th>\n",
              "      <td>Glazer makes new Man Utd approach\\n\\nMalcolm G...</td>\n",
              "      <td>A slimming aid made from a southern African ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1717</th>\n",
              "      <td>Five million Germans out of work\\n\\nGermany's ...</td>\n",
              "      <td>Job creation was one of last year's main conce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1718</th>\n",
              "      <td>Axa Sun Life cuts bonus payments\\n\\nLife insur...</td>\n",
              "      <td>Malcolm Glazer has made a fresh approach to bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1719</th>\n",
              "      <td>Amex shares up on spin-off news\\n\\nShares in A...</td>\n",
              "      <td>If admitted into the EU, Turkey would contribu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2220</th>\n",
              "      <td>GE sees 'excellent' world economy\\n\\nUS behemo...</td>\n",
              "      <td>The WTO said that many developing countries su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2221</th>\n",
              "      <td>Millions 'to lose textile jobs'\\n\\nMillions of...</td>\n",
              "      <td>Reuters news agency reported that Iraq's Oil M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2222</th>\n",
              "      <td>US to rule on Yukos refuge call\\n\\nYukos has s...</td>\n",
              "      <td>Parmalat has sued 45 banks as it tries to recl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2223</th>\n",
              "      <td>Business confidence dips in Japan\\n\\nBusiness ...</td>\n",
              "      <td>Bombardier said restructuring plans drawn up b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2224</th>\n",
              "      <td>Wall Street cheers Bush victory\\n\\nThe US stoc...</td>\n",
              "      <td>The Brazilian government has played down claim...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>510 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bfcb231b-3274-4085-8b82-091f9de79904')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bfcb231b-3274-4085-8b82-091f9de79904 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bfcb231b-3274-4085-8b82-091f9de79904');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_business = df_business.replace(r'\\n\\n',' ', regex=True)\n",
        "df_business"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "TujDzy_Lkyn8",
        "outputId": "e6ae5bf4-3855-4799-da46-a52763401c85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               articles  \\\n",
              "1715  EU 'too slow' on economic reforms Most EU coun...   \n",
              "1716  Glazer makes new Man Utd approach Malcolm Glaz...   \n",
              "1717  Five million Germans out of work Germany's une...   \n",
              "1718  Axa Sun Life cuts bonus payments Life insurer ...   \n",
              "1719  Amex shares up on spin-off news Shares in Amer...   \n",
              "...                                                 ...   \n",
              "2220  GE sees 'excellent' world economy US behemoth ...   \n",
              "2221  Millions 'to lose textile jobs' Millions of th...   \n",
              "2222  US to rule on Yukos refuge call Yukos has said...   \n",
              "2223  Business confidence dips in Japan Business con...   \n",
              "2224  Wall Street cheers Bush victory The US stock m...   \n",
              "\n",
              "                                              summaries  \n",
              "1715  Senator Kerry attacked President Bush's econom...  \n",
              "1716  A slimming aid made from a southern African ca...  \n",
              "1717  Job creation was one of last year's main conce...  \n",
              "1718  Malcolm Glazer has made a fresh approach to bu...  \n",
              "1719  If admitted into the EU, Turkey would contribu...  \n",
              "...                                                 ...  \n",
              "2220  The WTO said that many developing countries su...  \n",
              "2221  Reuters news agency reported that Iraq's Oil M...  \n",
              "2222  Parmalat has sued 45 banks as it tries to recl...  \n",
              "2223  Bombardier said restructuring plans drawn up b...  \n",
              "2224  The Brazilian government has played down claim...  \n",
              "\n",
              "[510 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-542a0004-dff8-4073-9861-59052cc9956f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>articles</th>\n",
              "      <th>summaries</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1715</th>\n",
              "      <td>EU 'too slow' on economic reforms Most EU coun...</td>\n",
              "      <td>Senator Kerry attacked President Bush's econom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1716</th>\n",
              "      <td>Glazer makes new Man Utd approach Malcolm Glaz...</td>\n",
              "      <td>A slimming aid made from a southern African ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1717</th>\n",
              "      <td>Five million Germans out of work Germany's une...</td>\n",
              "      <td>Job creation was one of last year's main conce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1718</th>\n",
              "      <td>Axa Sun Life cuts bonus payments Life insurer ...</td>\n",
              "      <td>Malcolm Glazer has made a fresh approach to bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1719</th>\n",
              "      <td>Amex shares up on spin-off news Shares in Amer...</td>\n",
              "      <td>If admitted into the EU, Turkey would contribu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2220</th>\n",
              "      <td>GE sees 'excellent' world economy US behemoth ...</td>\n",
              "      <td>The WTO said that many developing countries su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2221</th>\n",
              "      <td>Millions 'to lose textile jobs' Millions of th...</td>\n",
              "      <td>Reuters news agency reported that Iraq's Oil M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2222</th>\n",
              "      <td>US to rule on Yukos refuge call Yukos has said...</td>\n",
              "      <td>Parmalat has sued 45 banks as it tries to recl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2223</th>\n",
              "      <td>Business confidence dips in Japan Business con...</td>\n",
              "      <td>Bombardier said restructuring plans drawn up b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2224</th>\n",
              "      <td>Wall Street cheers Bush victory The US stock m...</td>\n",
              "      <td>The Brazilian government has played down claim...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>510 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-542a0004-dff8-4073-9861-59052cc9956f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-542a0004-dff8-4073-9861-59052cc9956f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-542a0004-dff8-4073-9861-59052cc9956f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_business[\"summaries\"] = \"summarize: \"+df_business[\"summaries\"]"
      ],
      "metadata": {
        "id": "6RPLMwliM06B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_business.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "G6uMPmOTM26G",
        "outputId": "f99d9043-29d5-4430-d9b0-46deb0dec865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               articles  \\\n",
              "1715  EU 'too slow' on economic reforms Most EU coun...   \n",
              "1716  Glazer makes new Man Utd approach Malcolm Glaz...   \n",
              "1717  Five million Germans out of work Germany's une...   \n",
              "1718  Axa Sun Life cuts bonus payments Life insurer ...   \n",
              "1719  Amex shares up on spin-off news Shares in Amer...   \n",
              "\n",
              "                                              summaries  \n",
              "1715  summarize: Senator Kerry attacked President Bu...  \n",
              "1716  summarize: A slimming aid made from a southern...  \n",
              "1717  summarize: Job creation was one of last year's...  \n",
              "1718  summarize: Malcolm Glazer has made a fresh app...  \n",
              "1719  summarize: If admitted into the EU, Turkey wou...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-31b27881-a7fe-433a-8164-c39075997030\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>articles</th>\n",
              "      <th>summaries</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1715</th>\n",
              "      <td>EU 'too slow' on economic reforms Most EU coun...</td>\n",
              "      <td>summarize: Senator Kerry attacked President Bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1716</th>\n",
              "      <td>Glazer makes new Man Utd approach Malcolm Glaz...</td>\n",
              "      <td>summarize: A slimming aid made from a southern...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1717</th>\n",
              "      <td>Five million Germans out of work Germany's une...</td>\n",
              "      <td>summarize: Job creation was one of last year's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1718</th>\n",
              "      <td>Axa Sun Life cuts bonus payments Life insurer ...</td>\n",
              "      <td>summarize: Malcolm Glazer has made a fresh app...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1719</th>\n",
              "      <td>Amex shares up on spin-off news Shares in Amer...</td>\n",
              "      <td>summarize: If admitted into the EU, Turkey wou...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31b27881-a7fe-433a-8164-c39075997030')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-31b27881-a7fe-433a-8164-c39075997030 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-31b27881-a7fe-433a-8164-c39075997030');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import os\n",
        "\n",
        "# Importing the T5 modules from huggingface/transformers\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "from rich.table import Column, Table\n",
        "from rich import box\n",
        "from rich.console import Console\n",
        "\n",
        "# define a rich console logger\n",
        "console=Console(record=True)\n",
        "\n",
        "def display_df(df):\n",
        "  \"\"\"display dataframe in ASCII format\"\"\"\n",
        "\n",
        "  console=Console()\n",
        "  table = Table(Column(\"source_text\", justify=\"center\" ), Column(\"target_text\", justify=\"center\"), title=\"Sample Data\",pad_edge=False, box=box.ASCII)\n",
        "\n",
        "  for i, row in enumerate(df.values.tolist()):\n",
        "    table.add_row(row[0], row[1])\n",
        "\n",
        "  console.print(table)\n",
        "\n",
        "training_logger = Table(Column(\"Epoch\", justify=\"center\" ), \n",
        "                        Column(\"Steps\", justify=\"center\"),\n",
        "                        Column(\"Loss\", justify=\"center\"), \n",
        "                        title=\"Training Status\",pad_edge=False, box=box.ASCII)"
      ],
      "metadata": {
        "id": "G9UtBc8tM7U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the device for GPU usage\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "GhVlUbrfM9Ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YourDataSetClass(Dataset):\n",
        "  \"\"\"\n",
        "  Creating a custom dataset for reading the dataset and \n",
        "  loading it into the dataloader to pass it to the neural network for finetuning the model\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, dataframe, tokenizer, source_len, target_len, source_text, target_text):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.data = dataframe\n",
        "    self.source_len = source_len\n",
        "    self.summ_len = target_len\n",
        "    self.target_text = self.data[target_text]\n",
        "    self.source_text = self.data[source_text]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.target_text)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    source_text = str(self.source_text[index])\n",
        "    target_text = str(self.target_text[index])\n",
        "\n",
        "    #cleaning data so as to ensure data is in string type\n",
        "    source_text = ' '.join(source_text.split())\n",
        "    target_text = ' '.join(target_text.split())\n",
        "\n",
        "    source = self.tokenizer.batch_encode_plus([source_text], max_length= self.source_len, pad_to_max_length=True, truncation=True, padding=\"max_length\", return_tensors='pt')\n",
        "    target = self.tokenizer.batch_encode_plus([target_text], max_length= self.summ_len, pad_to_max_length=True, truncation=True, padding=\"max_length\", return_tensors='pt')\n",
        "\n",
        "    source_ids = source['input_ids'].squeeze()\n",
        "    source_mask = source['attention_mask'].squeeze()\n",
        "    target_ids = target['input_ids'].squeeze()\n",
        "    target_mask = target['attention_mask'].squeeze()\n",
        "\n",
        "    return {\n",
        "        'source_ids': source_ids.to(dtype=torch.long), \n",
        "        'source_mask': source_mask.to(dtype=torch.long), \n",
        "        'target_ids': target_ids.to(dtype=torch.long),\n",
        "        'target_ids_y': target_ids.to(dtype=torch.long)\n",
        "    }"
      ],
      "metadata": {
        "id": "kS4zDtn-NBzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
        "\n",
        "  \"\"\"\n",
        "  Function to be called for training with the parameters passed from main function\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  model.train()\n",
        "  for _,data in enumerate(loader, 0):\n",
        "    y = data['target_ids'].to(device, dtype = torch.long)\n",
        "    y_ids = y[:, :-1].contiguous()\n",
        "    lm_labels = y[:, 1:].clone().detach()\n",
        "    lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
        "    ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "    mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "    outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n",
        "    loss = outputs[0]\n",
        "\n",
        "    if _%10==0:\n",
        "      training_logger.add_row(str(epoch), str(_), str(loss))\n",
        "      console.print(training_logger)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "s-hI5IsVNG3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(epoch, tokenizer, model, device, loader):\n",
        "\n",
        "  \"\"\"\n",
        "  Function to evaluate model for predictions\n",
        "\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  predictions = []\n",
        "  actuals = []\n",
        "  with torch.no_grad():\n",
        "      for _, data in enumerate(loader, 0):\n",
        "          y = data['target_ids'].to(device, dtype = torch.long)\n",
        "          ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "          mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "          generated_ids = model.generate(\n",
        "              input_ids = ids,\n",
        "              attention_mask = mask, \n",
        "              max_length=150, \n",
        "              num_beams=2,\n",
        "              repetition_penalty=2.5, \n",
        "              length_penalty=1.0, \n",
        "              early_stopping=True\n",
        "              )\n",
        "          preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
        "          target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
        "          if _%10==0:\n",
        "              console.print(f'Completed {_}')\n",
        "\n",
        "          predictions.extend(preds)\n",
        "          actuals.extend(target)\n",
        "  return predictions, actuals"
      ],
      "metadata": {
        "id": "dJ9KvreONHaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def T5Trainer(dataframe, source_text, target_text, model_params, output_dir=\"./outputs/\" ):\n",
        "  \n",
        "  \"\"\"\n",
        "  T5 trainer\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Set random seeds and deterministic pytorch for reproducibility\n",
        "  torch.manual_seed(model_params[\"SEED\"]) # pytorch random seed\n",
        "  np.random.seed(model_params[\"SEED\"]) # numpy random seed\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "\n",
        "  # logging\n",
        "  console.log(f\"\"\"[Model]: Loading {model_params[\"MODEL\"]}...\\n\"\"\")\n",
        "\n",
        "  # tokenzier for encoding the text\n",
        "  tokenizer = T5Tokenizer.from_pretrained(model_params[\"MODEL\"])\n",
        "\n",
        "  # Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary. \n",
        "  # Further this model is sent to device (GPU/TPU) for using the hardware.\n",
        "  model = T5ForConditionalGeneration.from_pretrained(model_params[\"MODEL\"])\n",
        "  model = model.to(device)\n",
        "  \n",
        "  # logging\n",
        "  console.log(f\"[Data]: Reading data...\\n\")\n",
        "\n",
        "  # Importing the raw dataset\n",
        "  dataframe = dataframe[[source_text,target_text]]\n",
        "  display_df(dataframe.head(2))\n",
        "\n",
        "  \n",
        "  # Creation of Dataset and Dataloader\n",
        "  # Defining the train size. So 80% of the data will be used for training and the rest for validation. \n",
        "  train_size = 0.8\n",
        "  train_dataset=dataframe.sample(frac=train_size,random_state = model_params[\"SEED\"])\n",
        "  val_dataset=dataframe.drop(train_dataset.index).reset_index(drop=True)\n",
        "  train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "  console.print(f\"FULL Dataset: {dataframe.shape}\")\n",
        "  console.print(f\"TRAIN Dataset: {train_dataset.shape}\")\n",
        "  console.print(f\"TEST Dataset: {val_dataset.shape}\\n\")\n",
        "\n",
        "\n",
        "  # Creating the Training and Validation dataset for further creation of Dataloader\n",
        "  training_set = YourDataSetClass(train_dataset, tokenizer, model_params[\"MAX_SOURCE_TEXT_LENGTH\"], model_params[\"MAX_TARGET_TEXT_LENGTH\"], source_text, target_text)\n",
        "  val_set = YourDataSetClass(val_dataset, tokenizer, model_params[\"MAX_SOURCE_TEXT_LENGTH\"], model_params[\"MAX_TARGET_TEXT_LENGTH\"], source_text, target_text)\n",
        "\n",
        "\n",
        "  # Defining the parameters for creation of dataloaders\n",
        "  train_params = {\n",
        "      'batch_size': model_params[\"TRAIN_BATCH_SIZE\"],\n",
        "      'shuffle': True,\n",
        "      'num_workers': 0\n",
        "      }\n",
        "\n",
        "\n",
        "  val_params = {\n",
        "      'batch_size': model_params[\"VALID_BATCH_SIZE\"],\n",
        "      'shuffle': False,\n",
        "      'num_workers': 0\n",
        "      }\n",
        "\n",
        "\n",
        "  # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
        "  training_loader = DataLoader(training_set, **train_params)\n",
        "  val_loader = DataLoader(val_set, **val_params)\n",
        "\n",
        "\n",
        "  # Defining the optimizer that will be used to tune the weights of the network in the training session. \n",
        "  optimizer = torch.optim.Adam(params =  model.parameters(), lr=model_params[\"LEARNING_RATE\"])\n",
        "\n",
        "\n",
        "  # Training loop\n",
        "  console.log(f'[Initiating Fine Tuning]...\\n')\n",
        "\n",
        "  for epoch in range(model_params[\"TRAIN_EPOCHS\"]):\n",
        "      train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
        "      \n",
        "  console.log(f\"[Saving Model]...\\n\")\n",
        "  #Saving the model after training\n",
        "  path = os.path.join(output_dir, \"model_files\")\n",
        "  model.save_pretrained(path)\n",
        "  tokenizer.save_pretrained(path)\n",
        "\n",
        "\n",
        "  # evaluating test dataset\n",
        "  console.log(f\"[Initiating Validation]...\\n\")\n",
        "  for epoch in range(model_params[\"VAL_EPOCHS\"]):\n",
        "    predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
        "    final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
        "    final_df.to_csv(os.path.join(output_dir,'predictions.csv'))\n",
        "  \n",
        "  console.save_text(os.path.join(output_dir,'logs.txt'))\n",
        "  \n",
        "  console.log(f\"[Validation Completed.]\\n\")\n",
        "  console.print(f\"\"\"[Model] Model saved @ {os.path.join(output_dir, \"model_files\")}\\n\"\"\")\n",
        "  console.print(f\"\"\"[Validation] Generation on Validation data saved @ {os.path.join(output_dir,'predictions.csv')}\\n\"\"\")\n",
        "  console.print(f\"\"\"[Logs] Logs saved @ {os.path.join(output_dir,'logs.txt')}\\n\"\"\")"
      ],
      "metadata": {
        "id": "M9Mepxs7NJTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_params={\n",
        "    \"MODEL\":\"t5-base\",             # model_type: t5-base/t5-large\n",
        "    \"TRAIN_BATCH_SIZE\":8,          # training batch size\n",
        "    \"VALID_BATCH_SIZE\":8,          # validation batch size\n",
        "    \"TRAIN_EPOCHS\":3,              # number of training epochs\n",
        "    \"VAL_EPOCHS\":1,                # number of validation epochs\n",
        "    \"LEARNING_RATE\":1e-4,          # learning rate\n",
        "    \"MAX_SOURCE_TEXT_LENGTH\":512,  # max length of source text\n",
        "    \"MAX_TARGET_TEXT_LENGTH\":50,   # max length of target text\n",
        "    \"SEED\": 42                     # set seed for reproducibility \n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "B9tMihWuNMBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T5Trainer(dataframe=df_business[:500], source_text=\"articles\", target_text=\"summaries\", model_params=model_params, output_dir=\"outputs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FlXkJrArNOCP",
        "outputId": "5adde02c-bdf3-4c3a-9002-da023526b369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[12:59:23]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m: Loading t5-base\u001b[33m...\u001b[0m                     \u001b[2m<ipython-input-32-b1eef7f6be59>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m14\u001b[0m\n",
              "\u001b[2;36m           \u001b[0m                                                \u001b[2m                                  \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12:59:23] </span><span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">]</span>: Loading t5-base<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-32-b1eef7f6be59&gt;:14</span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                  </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[12:59:33]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mData\u001b[1m]\u001b[0m: Reading data\u001b[33m...\u001b[0m                         \u001b[2m<ipython-input-32-b1eef7f6be59>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m25\u001b[0m\n",
              "\u001b[2;36m           \u001b[0m                                                \u001b[2m                                  \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12:59:33] </span><span style=\"font-weight: bold\">[</span>Data<span style=\"font-weight: bold\">]</span>: Reading data<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-32-b1eef7f6be59&gt;:25</span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                  </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                                         Sample Data                                         \u001b[0m\n",
              "+-------------------------------------------------------------------------------------------+\n",
              "|\u001b[1m                source_text                 \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                target_text                 \u001b[0m|\n",
              "|---------------------------------------------+---------------------------------------------|\n",
              "| EU 'too slow' on economic reforms Most EU   | summarize: Senator Kerry attacked President |\n",
              "|   countries have failed to put in place     | Bush's economic record during his campaign, |\n",
              "|policies aimed at making Europe the world's  |  hammering home the fact that a net 800,000 |\n",
              "| most competitive economy by the end of the  | jobs were lost during his term in office.The|\n",
              "|decade, a report says. The study, undertaken |     US stock market has closed higher in    |\n",
              "|by the European Commission, sought to assess |  response to George W Bush's victory in the |\n",
              "|how far the EU has moved towards meeting its |   presidential elections.The higher share   |\n",
              "| economic targets. In 2000, EU leaders at a  |   prices also reflect relief that a clear   |\n",
              "|   summit in Lisbon pledged the European     | winner has emerged from what proved to be a |\n",
              "|  economy would outstrip that of the US by   |   tight poll.The rise in oil prices partly  |\n",
              "|2010. Their economic targets became known as |   reflects the view that President Bush is  |\n",
              "|the Lisbon Agenda. But the Commission report |     less likely than Mr Kerry to release    |\n",
              "|says that, in most EU countries, the pace of |     supplies from the US' strategic oil     |\n",
              "|   economic reform has been too slow, and    |  reserve.In key swing states such as Ohio,  |\n",
              "|  fulfilling the Lisbon ambitions will be    | which has suffered substantial job losses in|\n",
              "|difficult - if not impossible. Only the UK,  |    the past four years, President Bush's    |\n",
              "| Finland, Belgium, Denmark, Ireland and the  |   handling of the economy became a crucial  |\n",
              "|Netherlands have actually followed up policy |   election issue.President Bush has placed  |\n",
              "|recommendations. Among the biggest laggards, |  reform of the pensions system at the heart |\n",
              "|  according to the report, are Greece and    |     of his economic agenda for a second     |\n",
              "|Italy. The Lisbon Agenda set out to increase | term.President Bush focused on the fact that|\n",
              "| the number of people employed in Europe by  |  two million jobs have been created in the  |\n",
              "| encouraging more older people and women to  |  past year, claiming that it has vindicated |\n",
              "| stay in the workforce. It also set out to   |    his tax-cutting agenda.The US' recent    |\n",
              "| raise the amount the private sector spends  |  economic performance has been mixed, with  |\n",
              "|on research and development, while bringing  |  solid growth offset by disappointingly low |\n",
              "|    about greater discipline over public     |  job creation figures, and mounting worries |\n",
              "|spending and debt levels. Combined with high | over a record budget deficit.Share prices in|\n",
              "|environmental standards and efforts to level |   London, Frankfurt and Paris also closed   |\n",
              "|the playing field for businesses throughout  | higher.Some analysts predicted that the jump|\n",
              "| the EU, the plan was for Europe to become   | in share prices would be short-lived, saying|\n",
              "| the world's most dynamic economy by 2010.   | investors would quickly focus once again on |\n",
              "|   Next week, the Commission will present    |        the health of the US economy.        |\n",
              "|revised proposals to meet the Lisbon goals.  |                                             |\n",
              "|  Many people expect the 2010 target to be   |                                             |\n",
              "|              quietly dropped.               |                                             |\n",
              "|                                             |                                             |\n",
              "| Glazer makes new Man Utd approach Malcolm   |    summarize: A slimming aid made from a    |\n",
              "|  Glazer has made a fresh approach to buy    |     southern African cactus is set to be    |\n",
              "|Manchester United, which could lead to a bid |     developed by UK firm Phytopharm and     |\n",
              "|valuing the Premiership club at Â£800m. The  |  Unilever.Under the deal, production of the |\n",
              "|US tycoon, who has been wooing the club for  |   Hoodia cactus at Phytopharm's nursery in  |\n",
              "|   the last 12 months, has approached the    |    South Africa will also rise from eight   |\n",
              "| United board with \"detailed proposals\", it  |  million plants to potentially hundreds of  |\n",
              "|has confirmed. Mr Glazer, who owns the Tampa |  millions, said Phytopharm chief executive  |\n",
              "|Bay Buccaneers team, hopes this will lead to |   Richard Dixey.Phytopharm will receive an  |\n",
              "| a formal bid being accepted. His new offer  | initial fee of Â£6.5m from Unilever - out of|\n",
              "| is expected to contain substantially less   |   a potential total of Â£21m - as well as   |\n",
              "|debt. Mr Glazer has already had one takeover |  future royalties on product sales.The firm |\n",
              "| attempt turned down by the Red Devils and   |   had initially hoped to market a slimming  |\n",
              "|responded by using his 28.1% shareholding to |   drug from Hoodia with Pfizer.Anglo-Dutch  |\n",
              "|vote off three board members last November.  |      food giant Unilever will help the      |\n",
              "| Man United had turned down the bid because  |    pharmaceutical firm develop the snacks   |\n",
              "| it was based on a high level of borrowing.  |          containing Hoodia extract.         |\n",
              "|But newspapers have speculated recently that |                                             |\n",
              "|the tycoon had gained the support of leading |                                             |\n",
              "| banks to come up with a stronger and less   |                                             |\n",
              "|   debt-laden bid. Last week, however, Mr    |                                             |\n",
              "|   Glazer issued a statement to the Stock    |                                             |\n",
              "|Exchange distancing himself from a new bid.  |                                             |\n",
              "| Meanwhile, United's chief executive David   |                                             |\n",
              "| Gill said in December that talks would not  |                                             |\n",
              "|     resume unless Glazer came up with       |                                             |\n",
              "| \"definitive proposals\". Now the board has   |                                             |\n",
              "|confirmed that the US bidder is back, with a |                                             |\n",
              "|  statement issued on Sunday reading: \"The   |                                             |\n",
              "|  board can confirm it has now received a    |                                             |\n",
              "|    detailed proposal subject to various     |                                             |\n",
              "|preconditions which may form the basis of an |                                             |\n",
              "|offer. \"A further announcement will be made  |                                             |\n",
              "| in due course.\" To succeed Malcolm Glazer   |                                             |\n",
              "|   will still need the approval of major     |                                             |\n",
              "| shareholders John Magnier and JP McManus,   |                                             |\n",
              "|who own 28.9% of the club. But the Irish duo |                                             |\n",
              "|  have cut off talks with Glazer over the    |                                             |\n",
              "|proposed sale of their stake and have so far |                                             |\n",
              "|  made no comment on his latest approach.    |                                             |\n",
              "| United fans have reacted with anger at the  |                                             |\n",
              "| announcement. They have vehemently opposed  |                                             |\n",
              "|  any proposed takeover by Glazer since he   |                                             |\n",
              "|    first showed interest in the club in     |                                             |\n",
              "|     September 2003 and after Sunday's       |                                             |\n",
              "|  announcement they vowed to fight on. \"We   |                                             |\n",
              "|   will fight tooth and nail to stop him     |                                             |\n",
              "|whatever his offer says. We do not want him  |                                             |\n",
              "| or anybody else taking over United,\" said   |                                             |\n",
              "| Mark Longden of the Independent Manchester  |                                             |\n",
              "|    United Supporters' Association. \"The     |                                             |\n",
              "|campaign against this proposed takeover will |                                             |\n",
              "| continue as it has done since Glazer first  |                                             |\n",
              "|       showed interest in the club.\"         |                                             |\n",
              "|                                             |                                             |\n",
              "+-------------------------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                         Sample Data                                         </span>\n",
              "+-------------------------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">                source_text                  </span>|<span style=\"font-weight: bold\">                 target_text                 </span>|\n",
              "|---------------------------------------------+---------------------------------------------|\n",
              "| EU 'too slow' on economic reforms Most EU   | summarize: Senator Kerry attacked President |\n",
              "|   countries have failed to put in place     | Bush's economic record during his campaign, |\n",
              "|policies aimed at making Europe the world's  |  hammering home the fact that a net 800,000 |\n",
              "| most competitive economy by the end of the  | jobs were lost during his term in office.The|\n",
              "|decade, a report says. The study, undertaken |     US stock market has closed higher in    |\n",
              "|by the European Commission, sought to assess |  response to George W Bush's victory in the |\n",
              "|how far the EU has moved towards meeting its |   presidential elections.The higher share   |\n",
              "| economic targets. In 2000, EU leaders at a  |   prices also reflect relief that a clear   |\n",
              "|   summit in Lisbon pledged the European     | winner has emerged from what proved to be a |\n",
              "|  economy would outstrip that of the US by   |   tight poll.The rise in oil prices partly  |\n",
              "|2010. Their economic targets became known as |   reflects the view that President Bush is  |\n",
              "|the Lisbon Agenda. But the Commission report |     less likely than Mr Kerry to release    |\n",
              "|says that, in most EU countries, the pace of |     supplies from the US' strategic oil     |\n",
              "|   economic reform has been too slow, and    |  reserve.In key swing states such as Ohio,  |\n",
              "|  fulfilling the Lisbon ambitions will be    | which has suffered substantial job losses in|\n",
              "|difficult - if not impossible. Only the UK,  |    the past four years, President Bush's    |\n",
              "| Finland, Belgium, Denmark, Ireland and the  |   handling of the economy became a crucial  |\n",
              "|Netherlands have actually followed up policy |   election issue.President Bush has placed  |\n",
              "|recommendations. Among the biggest laggards, |  reform of the pensions system at the heart |\n",
              "|  according to the report, are Greece and    |     of his economic agenda for a second     |\n",
              "|Italy. The Lisbon Agenda set out to increase | term.President Bush focused on the fact that|\n",
              "| the number of people employed in Europe by  |  two million jobs have been created in the  |\n",
              "| encouraging more older people and women to  |  past year, claiming that it has vindicated |\n",
              "| stay in the workforce. It also set out to   |    his tax-cutting agenda.The US' recent    |\n",
              "| raise the amount the private sector spends  |  economic performance has been mixed, with  |\n",
              "|on research and development, while bringing  |  solid growth offset by disappointingly low |\n",
              "|    about greater discipline over public     |  job creation figures, and mounting worries |\n",
              "|spending and debt levels. Combined with high | over a record budget deficit.Share prices in|\n",
              "|environmental standards and efforts to level |   London, Frankfurt and Paris also closed   |\n",
              "|the playing field for businesses throughout  | higher.Some analysts predicted that the jump|\n",
              "| the EU, the plan was for Europe to become   | in share prices would be short-lived, saying|\n",
              "| the world's most dynamic economy by 2010.   | investors would quickly focus once again on |\n",
              "|   Next week, the Commission will present    |        the health of the US economy.        |\n",
              "|revised proposals to meet the Lisbon goals.  |                                             |\n",
              "|  Many people expect the 2010 target to be   |                                             |\n",
              "|              quietly dropped.               |                                             |\n",
              "|                                             |                                             |\n",
              "| Glazer makes new Man Utd approach Malcolm   |    summarize: A slimming aid made from a    |\n",
              "|  Glazer has made a fresh approach to buy    |     southern African cactus is set to be    |\n",
              "|Manchester United, which could lead to a bid |     developed by UK firm Phytopharm and     |\n",
              "|valuing the Premiership club at Â£800m. The  |  Unilever.Under the deal, production of the |\n",
              "|US tycoon, who has been wooing the club for  |   Hoodia cactus at Phytopharm's nursery in  |\n",
              "|   the last 12 months, has approached the    |    South Africa will also rise from eight   |\n",
              "| United board with \"detailed proposals\", it  |  million plants to potentially hundreds of  |\n",
              "|has confirmed. Mr Glazer, who owns the Tampa |  millions, said Phytopharm chief executive  |\n",
              "|Bay Buccaneers team, hopes this will lead to |   Richard Dixey.Phytopharm will receive an  |\n",
              "| a formal bid being accepted. His new offer  | initial fee of Â£6.5m from Unilever - out of|\n",
              "| is expected to contain substantially less   |   a potential total of Â£21m - as well as   |\n",
              "|debt. Mr Glazer has already had one takeover |  future royalties on product sales.The firm |\n",
              "| attempt turned down by the Red Devils and   |   had initially hoped to market a slimming  |\n",
              "|responded by using his 28.1% shareholding to |   drug from Hoodia with Pfizer.Anglo-Dutch  |\n",
              "|vote off three board members last November.  |      food giant Unilever will help the      |\n",
              "| Man United had turned down the bid because  |    pharmaceutical firm develop the snacks   |\n",
              "| it was based on a high level of borrowing.  |          containing Hoodia extract.         |\n",
              "|But newspapers have speculated recently that |                                             |\n",
              "|the tycoon had gained the support of leading |                                             |\n",
              "| banks to come up with a stronger and less   |                                             |\n",
              "|   debt-laden bid. Last week, however, Mr    |                                             |\n",
              "|   Glazer issued a statement to the Stock    |                                             |\n",
              "|Exchange distancing himself from a new bid.  |                                             |\n",
              "| Meanwhile, United's chief executive David   |                                             |\n",
              "| Gill said in December that talks would not  |                                             |\n",
              "|     resume unless Glazer came up with       |                                             |\n",
              "| \"definitive proposals\". Now the board has   |                                             |\n",
              "|confirmed that the US bidder is back, with a |                                             |\n",
              "|  statement issued on Sunday reading: \"The   |                                             |\n",
              "|  board can confirm it has now received a    |                                             |\n",
              "|    detailed proposal subject to various     |                                             |\n",
              "|preconditions which may form the basis of an |                                             |\n",
              "|offer. \"A further announcement will be made  |                                             |\n",
              "| in due course.\" To succeed Malcolm Glazer   |                                             |\n",
              "|   will still need the approval of major     |                                             |\n",
              "| shareholders John Magnier and JP McManus,   |                                             |\n",
              "|who own 28.9% of the club. But the Irish duo |                                             |\n",
              "|  have cut off talks with Glazer over the    |                                             |\n",
              "|proposed sale of their stake and have so far |                                             |\n",
              "|  made no comment on his latest approach.    |                                             |\n",
              "| United fans have reacted with anger at the  |                                             |\n",
              "| announcement. They have vehemently opposed  |                                             |\n",
              "|  any proposed takeover by Glazer since he   |                                             |\n",
              "|    first showed interest in the club in     |                                             |\n",
              "|     September 2003 and after Sunday's       |                                             |\n",
              "|  announcement they vowed to fight on. \"We   |                                             |\n",
              "|   will fight tooth and nail to stop him     |                                             |\n",
              "|whatever his offer says. We do not want him  |                                             |\n",
              "| or anybody else taking over United,\" said   |                                             |\n",
              "| Mark Longden of the Independent Manchester  |                                             |\n",
              "|    United Supporters' Association. \"The     |                                             |\n",
              "|campaign against this proposed takeover will |                                             |\n",
              "| continue as it has done since Glazer first  |                                             |\n",
              "|       showed interest in the club.\"         |                                             |\n",
              "|                                             |                                             |\n",
              "+-------------------------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FULL Dataset: \u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">FULL Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "TRAIN Dataset: \u001b[1m(\u001b[0m\u001b[1;36m400\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TRAIN Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "TEST Dataset: \u001b[1m(\u001b[0m\u001b[1;36m100\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TEST Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mInitiating Fine Tuning\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                     \u001b[2m<ipython-input-32-b1eef7f6be59>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m74\u001b[0m\n",
              "\u001b[2;36m           \u001b[0m                                                \u001b[2m                                  \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">[</span>Initiating Fine Tuning<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-32-b1eef7f6be59&gt;:74</span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                  </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(4.6706, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(4.6706, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(4.6706, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(4.4262, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(4.6706, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(4.4262, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(4.6706, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(4.4262, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(4.0932, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(4.6706, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(4.4262, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(4.0932, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(4.6706, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(4.4262, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(4.0932, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(3.8610, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(4.6706, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(4.4262, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(4.0932, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(3.8610, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(4.6706, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(4.4262, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(4.0932, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(3.8610, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(3.8801, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(4.6706, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(4.4262, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(4.0932, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(3.8610, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(3.8801, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(4.6706, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(4.4262, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(4.0932, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(3.8610, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(3.8801, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  20   | tensor(3.8774, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(4.6706, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(4.4262, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(4.0932, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(3.8610, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(3.8801, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  20   | tensor(3.8774, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(4.6706, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(4.4262, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(4.0932, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(3.8610, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(3.8801, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  20   | tensor(3.8774, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  30   | tensor(3.8047, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(4.6706, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(4.4262, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(4.0932, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(3.8610, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(3.8801, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  20   | tensor(3.8774, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  30   | tensor(3.8047, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(4.6706, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(4.4262, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(4.0932, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(3.8610, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(3.8801, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  20   | tensor(3.8774, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  30   | tensor(3.8047, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  40   | tensor(3.4742, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(4.6706, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(4.4262, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(4.0932, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(3.8610, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(3.8801, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  20   | tensor(3.8774, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  30   | tensor(3.8047, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  40   | tensor(3.4742, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(4.6706, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(4.4262, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(4.0932, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(3.8610, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(3.8801, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  20   | tensor(3.8774, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  30   | tensor(3.8047, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  40   | tensor(3.4742, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |   0   | tensor(3.6056, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(4.6706, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(4.4262, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(4.0932, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(3.8610, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(3.8801, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  20   | tensor(3.8774, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  30   | tensor(3.8047, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  40   | tensor(3.4742, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |   0   | tensor(3.6056, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(4.6706, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(4.4262, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(4.0932, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(3.8610, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(3.8801, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  20   | tensor(3.8774, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  30   | tensor(3.8047, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  40   | tensor(3.4742, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |   0   | tensor(3.6056, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  10   | tensor(3.6461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(4.6706, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(4.4262, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(4.0932, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(3.8610, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(3.8801, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  20   | tensor(3.8774, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  30   | tensor(3.8047, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  40   | tensor(3.4742, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |   0   | tensor(3.6056, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  10   | tensor(3.6461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(4.6706, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(4.4262, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(4.0932, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(3.8610, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(3.8801, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  20   | tensor(3.8774, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  30   | tensor(3.8047, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  40   | tensor(3.4742, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |   0   | tensor(3.6056, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  10   | tensor(3.6461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  20   | tensor(3.5706, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(4.6706, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(4.4262, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(4.0932, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(3.8610, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(3.8801, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  20   | tensor(3.8774, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  30   | tensor(3.8047, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  40   | tensor(3.4742, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |   0   | tensor(3.6056, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  10   | tensor(3.6461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  20   | tensor(3.5706, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(4.6706, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(4.4262, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(4.0932, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(3.8610, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(3.8801, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  20   | tensor(3.8774, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  30   | tensor(3.8047, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  40   | tensor(3.4742, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |   0   | tensor(3.6056, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  10   | tensor(3.6461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  20   | tensor(3.5706, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  30   | tensor(3.8232, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(4.6706, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(4.4262, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(4.0932, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(3.8610, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(3.8801, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  20   | tensor(3.8774, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  30   | tensor(3.8047, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  40   | tensor(3.4742, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |   0   | tensor(3.6056, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  10   | tensor(3.6461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  20   | tensor(3.5706, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  30   | tensor(3.8232, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(4.6706, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(4.4262, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(4.0932, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(3.8610, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(3.8801, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  20   | tensor(3.8774, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  30   | tensor(3.8047, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  40   | tensor(3.4742, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |   0   | tensor(3.6056, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  10   | tensor(3.6461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  20   | tensor(3.5706, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  30   | tensor(3.8232, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  40   | tensor(3.3871, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(8.1378, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(4.9086, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(4.6706, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(4.4262, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(4.0932, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(3.8610, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(3.8801, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  20   | tensor(3.8774, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  30   | tensor(3.8047, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  40   | tensor(3.4742, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |   0   | tensor(3.6056, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  10   | tensor(3.6461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  20   | tensor(3.5706, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  30   | tensor(3.8232, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  40   | tensor(3.3871, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[13:01:09]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mSaving Model\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                               \u001b[2m<ipython-input-32-b1eef7f6be59>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m79\u001b[0m\n",
              "\u001b[2;36m           \u001b[0m                                                \u001b[2m                                  \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[13:01:09] </span><span style=\"font-weight: bold\">[</span>Saving Model<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-32-b1eef7f6be59&gt;:79</span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                  </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[13:01:11]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mInitiating Validation\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                      \u001b[2m<ipython-input-32-b1eef7f6be59>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m87\u001b[0m\n",
              "\u001b[2;36m           \u001b[0m                                                \u001b[2m                                  \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[13:01:11] </span><span style=\"font-weight: bold\">[</span>Initiating Validation<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-32-b1eef7f6be59&gt;:87</span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                  </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Completed \u001b[1;36m0\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Completed \u001b[1;36m10\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[13:02:08]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mValidation Completed.\u001b[1m]\u001b[0m                         \u001b[2m<ipython-input-32-b1eef7f6be59>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m95\u001b[0m\n",
              "\u001b[2;36m           \u001b[0m                                                \u001b[2m                                  \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[13:02:08] </span><span style=\"font-weight: bold\">[</span>Validation Completed.<span style=\"font-weight: bold\">]</span>                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-32-b1eef7f6be59&gt;:95</span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                  </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m Model saved @ outputs/model_files\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">]</span> Model saved @ outputs/model_files\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mValidation\u001b[1m]\u001b[0m Generation on Validation data saved @ outputs/predictions.csv\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Validation<span style=\"font-weight: bold\">]</span> Generation on Validation data saved @ outputs/predictions.csv\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mLogs\u001b[1m]\u001b[0m Logs saved @ outputs/logs.txt\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Logs<span style=\"font-weight: bold\">]</span> Logs saved @ outputs/logs.txt\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}